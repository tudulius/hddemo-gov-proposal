import streamlit as st
from anthropic import Anthropic
from groq import Groq
import json
import PyPDF2
import io

st.set_page_config(
    page_title="ì •ë¶€ì§€ì›ê³¼ì œ ì‚¬ì—…ê³„íšì„œ ì‘ì„±ê¸°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ëª¨ë¸ ì„¤ì •
CLAUDE_MODELS = {
    "claude-3-opus-20240229": {
        "name": "Claude 3 Opus",
        "description": "ê°€ì¥ ê°•ë ¥í•œ ì„±ëŠ¥, ë³µì¡í•œ ì‘ì—…ì— ì í•©",
        "max_tokens": 4000
    },
    "claude-3-sonnet-20240229": {
        "name": "Claude 3 Sonnet",
        "description": "ê· í˜• ì¡íŒ ì„±ëŠ¥ê³¼ ì†ë„",
        "max_tokens": 4000
    },
    "claude-3-haiku-20240229": {
        "name": "Claude 3 Haiku",
        "description": "ë¹ ë¥¸ ì†ë„, ê°„ë‹¨í•œ ì‘ì—…ì— ì í•©",
        "max_tokens": 4000
    },
    "claude-3.5-sonnet": {
        "name": "Claude 3.5 Sonnet",
        "description": "í–¥ìƒëœ ì„±ëŠ¥ì˜ Sonnet ëª¨ë¸, ë³µì¡í•œ ì‘ì—…ë„ ë¹ ë¥´ê²Œ ì²˜ë¦¬",
        "max_tokens": 4000
    }
}

GROQ_MODELS = {
    "mixtral-8x7b-32768": {
        "name": "Mixtral 8x7B",
        "description": "ìµœì‹  ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸, ë‹¤ì–‘í•œ ì‘ì—…ì— ì í•©",
        "max_tokens": 4000
    },
    "llama2-70b-4096": {
        "name": "LLaMA 2 70B",
        "description": "ì•ˆì •ì ì¸ ì„±ëŠ¥ì˜ ëŒ€í˜• ëª¨ë¸",
        "max_tokens": 4000
    },
    "deepseek-r1-distill-qwen-32b": {
        "name": "DeepSeek R1 Distill QWAN",
        "description": "ê³ ì„±ëŠ¥ ì••ì¶• ëª¨ë¸, ë¹ ë¥¸ ì‘ë‹µ ì†ë„",
        "max_tokens": 4000
    },
    "qwan-2.5-coder-32b": {
        "name": "QWAN 2.5 Coder",
        "description": "ì½”ë”© íŠ¹í™” ëª¨ë¸, ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ì— ê°•ì ",
        "max_tokens": 4000
    }
}

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("ğŸ”§ ì„¤ì •")
    
    # LLM ì„ íƒ
    llm_provider = st.radio(
        "AI ëª¨ë¸ ì œê³µì ì„ íƒ",
        ["Claude", "Groq"],
        help="ê° ì œê³µìë³„ íŠ¹ì§•:\n- Claude: ë†’ì€ í’ˆì§ˆì˜ í…ìŠ¤íŠ¸ ìƒì„±\n- Groq: ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„"
    )
    
    if llm_provider == "Claude":
        # Claude API í‚¤ ì…ë ¥ ë°›ê¸°
        api_key = st.text_input("Claude API Key", type="password")
        if not api_key:
            st.info("Claude API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ—ï¸")
            st.stop()

        # Anthropic í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        try:
            client = Anthropic(api_key=api_key)
            model_options = list(CLAUDE_MODELS.keys())
            
            # ëª¨ë¸ì„ ì„±ëŠ¥ ìˆœì„œëŒ€ë¡œ ì •ë ¬
            model_order = {
                "claude-3-opus-20240229": 1,
                "claude-3.5-sonnet": 2,
                "claude-3-sonnet-20240229": 3,
                "claude-3-haiku-20240229": 4
            }
            model_options.sort(key=lambda x: model_order.get(x, 999))
            
            selected_model = st.selectbox(
                "Claude ëª¨ë¸ ì„ íƒ",
                model_options,
                format_func=lambda x: f"{CLAUDE_MODELS[x]['name']} - {CLAUDE_MODELS[x]['description']}",
                help="ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”. ìœ„ì—ì„œë¶€í„° ì„±ëŠ¥ì´ ì¢‹ì€ ìˆœì„œì…ë‹ˆë‹¤."
            )
            
            # ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
            st.info(CLAUDE_MODELS[selected_model]["description"])
            
        except Exception as e:
            st.error(f"API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•Šê±°ë‚˜ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.stop()

    else:  # Groq
        # Groq API í‚¤ ì…ë ¥ ë°›ê¸°
        api_key = st.text_input("Groq API Key", type="password")
        if not api_key:
            st.info("Groq API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ—ï¸")
            st.stop()

        # Groq í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        try:
            client = Groq(api_key=api_key)
            model_options = list(GROQ_MODELS.keys())
            selected_model = st.selectbox(
                "Groq ëª¨ë¸ ì„ íƒ",
                model_options,
                format_func=lambda x: GROQ_MODELS[x]["name"],
                help="ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # ì„ íƒëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
            st.info(GROQ_MODELS[selected_model]["description"])
            
        except Exception as e:
            st.error(f"API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•Šê±°ë‚˜ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.stop()
    
    # ê³ ê¸‰ ì„¤ì •
    with st.expander("ğŸ› ï¸ ê³ ê¸‰ ì„¤ì •"):
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=1.0,
            value=0.7,
            step=0.1,
            help="ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì¸ ê²°ê³¼ê°€ ìƒì„±ë©ë‹ˆë‹¤"
        )
        
        max_tokens = st.number_input(
            "ìµœëŒ€ í† í° ìˆ˜",
            min_value=1000,
            max_value=4000,
            value=4000,
            step=500,
            help="ìƒì„±ë  í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´"
        )
    
    # ëª¨ë¸ ì •ë³´ í‘œì‹œ
    st.divider()
    st.markdown("### ì„ íƒëœ ëª¨ë¸ ì •ë³´")
    model_info = CLAUDE_MODELS[selected_model] if llm_provider == "Claude" else GROQ_MODELS[selected_model]
    st.info(
        f"ì œê³µì: {llm_provider}\n"
        f"ëª¨ë¸: {model_info['name']}\n"
        f"íŠ¹ì§•: {model_info['description']}"
    )

# ë©”ì¸ í™”ë©´
st.title("ğŸ¢ ì •ë¶€ì§€ì›ê³¼ì œ ì‚¬ì—…ê³„íšì„œ ì‘ì„±ê¸°")
st.write(
    "ê³µê³ ë¬¸ PDFì™€ íšŒì‚¬ ì •ë³´ë¥¼ ì…ë ¥í•˜ì‹œë©´, AIê°€ ë§ì¶¤í˜• ì‚¬ì—…ê³„íšì„œë¥¼ ì‘ì„±í•´ë“œë¦½ë‹ˆë‹¤. "
    "ì´ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì‹œë ¤ë©´ Claude ë˜ëŠ” Groq API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
)

# PDF íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ê³µê³ ë¬¸ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”", type="pdf")
announcement_text = ""

if uploaded_file is not None:
    try:
        # PDF íŒŒì¼ ì½ê¸°
        pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))
        
        # ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        announcement_text = ""
        for page in pdf_reader.pages:
            announcement_text += page.extract_text() + "\n"
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
        st.subheader("ğŸ“„ ì¶”ì¶œëœ ê³µê³ ë¬¸ ë‚´ìš©")
        with st.expander("ê³µê³ ë¬¸ ë‚´ìš© ë³´ê¸°"):
            st.text(announcement_text)
            
    except Exception as e:
        st.error(f"PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.stop()

# íšŒì‚¬ ì •ë³´ ì…ë ¥
st.subheader("íšŒì‚¬ ì •ë³´ ì…ë ¥")
col1, col2 = st.columns(2)

with col1:
    company_name = st.text_input("íšŒì‚¬ëª…")
    business_number = st.text_input("ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸")
    ceo_name = st.text_input("ëŒ€í‘œìëª…")
    establishment_date = st.date_input("ì„¤ë¦½ì¼ì")
    
with col2:
    employee_count = st.number_input("ì§ì› ìˆ˜", min_value=1)
    annual_revenue = st.number_input("ì—°ê°„ ë§¤ì¶œì•¡(ë°±ë§Œì›)", min_value=0)
    main_business = st.text_area("ì£¼ìš” ì‚¬ì—…ë‚´ìš©", height=100)
    company_address = st.text_input("íšŒì‚¬ ì£¼ì†Œ")

if st.button("ì‚¬ì—…ê³„íšì„œ ìƒì„±", type="primary"):
    if not (announcement_text and company_name and business_number and ceo_name and main_business):
        st.error("ê³µê³ ë¬¸ PDFì™€ ëª¨ë“  í•„ìˆ˜ í•­ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
        
    # íšŒì‚¬ ì •ë³´ êµ¬ì¡°í™”
    company_info = {
        "íšŒì‚¬ëª…": company_name,
        "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸": business_number,
        "ëŒ€í‘œìëª…": ceo_name,
        "ì„¤ë¦½ì¼ì": establishment_date.strftime("%Y-%m-%d"),
        "ì§ì›ìˆ˜": employee_count,
        "ì—°ê°„ë§¤ì¶œì•¡": f"{annual_revenue}ë°±ë§Œì›",
        "ì£¼ìš”ì‚¬ì—…ë‚´ìš©": main_business,
        "íšŒì‚¬ì£¼ì†Œ": company_address
    }
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ì•„ë˜ì˜ ì •ë¶€ì§€ì›ê³¼ì œ ê³µê³ ë¬¸ê³¼ íšŒì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•½ 30í˜ì´ì§€ ë¶„ëŸ‰ì˜ ìƒì„¸í•œ ì‚¬ì—…ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ê³µê³ ë¬¸:
{announcement_text}

íšŒì‚¬ ì •ë³´:
{json.dumps(company_info, ensure_ascii=False, indent=2)}

ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ì‚¬ì—…ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. ì‚¬ì—… ê°œìš”
2. ê¸°ì—… í˜„í™©
3. ì‚¬ì—… ëª©í‘œ ë° ë‚´ìš©
4. ì¶”ì§„ ì „ëµ ë° ë°©ë²•
5. ì‚¬ì—… ìˆ˜í–‰ ì²´ê³„
6. ê¸°ëŒ€íš¨ê³¼
7. ì†Œìš”ì˜ˆì‚°
8. í–¥í›„ ê³„íš

ê° ì„¹ì…˜ì„ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ë˜, ê³µê³ ë¬¸ì˜ ìš”êµ¬ì‚¬í•­ê³¼ íšŒì‚¬ì˜ ê°•ì ì´ ì˜ ë¶€í•©ë˜ë„ë¡ ì‘ì„±í•´ì£¼ì„¸ìš”.
íŠ¹íˆ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ì¤‘ì ì ìœ¼ë¡œ ë°˜ì˜í•´ì£¼ì„¸ìš”:
1. ê³µê³ ë¬¸ì˜ ì§€ì›ìê²©ê³¼ íšŒì‚¬ì˜ ì ê²©ì„±
2. ê³µê³ ë¬¸ì˜ ìš°ëŒ€ì‚¬í•­ê³¼ íšŒì‚¬ì˜ ì¥ì 
3. ê³µê³ ë¬¸ì˜ í‰ê°€ê¸°ì¤€ê³¼ íšŒì‚¬ì˜ ê°•ì 
4. ì§€ì›ê¸ˆì•¡ í•œë„ì™€ ì˜ˆì‚° ê³„íšì˜ ì ì ˆì„±"""

    try:
        with st.spinner('ì‚¬ì—…ê³„íšì„œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì•½ 2-3ë¶„ ì†Œìš”)'):
            if llm_provider == "Claude":
                # Claude API í˜¸ì¶œ
                message = client.messages.create(
                    model=selected_model,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    messages=[{
                        "role": "user",
                        "content": prompt
                    }]
                )
                response_text = message.content[0].text
            else:
                # Groq API í˜¸ì¶œ
                completion = client.chat.completions.create(
                    model=selected_model,
                    messages=[{
                        "role": "user",
                        "content": prompt
                    }],
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=False
                )
                response_text = completion.choices[0].message.content
            
            # ê²°ê³¼ë¥¼ íƒ­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
            tab1, tab2, tab3 = st.tabs(["ğŸ“ ë¯¸ë¦¬ë³´ê¸°", "ğŸ“Š ë¶„ì„", "âš™ï¸ ì„¤ì •"])
            
            with tab1:
                st.success("ì‚¬ì—…ê³„íšì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.markdown(response_text)
                
                col1, col2 = st.columns([1, 2])
                with col1:
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (TXT)
                    st.download_button(
                        label="TXT í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=response_text,
                        file_name=f"{company_name}_ì‚¬ì—…ê³„íšì„œ.txt",
                        mime="text/plain"
                    )
                with col2:
                    # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
                    st.download_button(
                        label="ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        data=response_text,
                        file_name=f"{company_name}_ì‚¬ì—…ê³„íšì„œ.md",
                        mime="text/markdown"
                    )
                
            with tab2:
                st.subheader("ê³µê³ ë¬¸ ë¶„ì„ ê²°ê³¼")
                analysis_prompt = f"""ë‹¤ìŒ ê³µê³ ë¬¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ìš”êµ¬ì‚¬í•­ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
                1. ì§€ì›ìê²© ìš”ê±´
                2. ìš°ëŒ€ì‚¬í•­
                3. í‰ê°€ ê¸°ì¤€
                4. ì§€ì›ê¸ˆì•¡ í•œë„
                5. ì£¼ì˜ì‚¬í•­
                
                ê³µê³ ë¬¸:
                {announcement_text}
                """
                
                if llm_provider == "Claude":
                    analysis = client.messages.create(
                        model=selected_model,
                        max_tokens=2000,
                        temperature=0.3,
                        messages=[{"role": "user", "content": analysis_prompt}]
                    )
                    analysis_text = analysis.content[0].text
                else:
                    analysis = client.chat.completions.create(
                        model=selected_model,
                        messages=[{"role": "user", "content": analysis_prompt}],
                        temperature=0.3,
                        max_tokens=2000,
                        stream=False
                    )
                    analysis_text = analysis.choices[0].message.content
                
                st.markdown(analysis_text)
            
            with tab3:
                st.subheader("ìƒì„± ì„¤ì •")
                st.json({
                    "AI ì œê³µì": llm_provider,
                    "ëª¨ë¸ëª…": model_info["name"],
                    "ëª¨ë¸ ì„¤ëª…": model_info["description"],
                    "ìµœëŒ€ í† í°": max_tokens,
                    "Temperature": temperature
                })
            
    except Exception as e:
        st.error(f"ì‚¬ì—…ê³„íšì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        if "model_not_found" in str(e):
            st.warning("ì„ íƒí•œ ëª¨ë¸ì´ í˜„ì¬ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.info("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤...")